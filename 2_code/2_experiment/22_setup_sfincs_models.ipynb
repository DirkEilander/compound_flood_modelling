{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydromt_sfincs import SfincsModel\n",
    "from hydromt.config import configread\n",
    "from hydromt.log import setuplog\n",
    "from os.path import join, isfile, isdir\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model and data paths\n",
    "model_root = r'../../3_models/SFINCS2'\n",
    "data_libs = [\n",
    "    r'../../1_data/1_static/static_data.yml',\n",
    "    r'../../1_data/2_forcing/forcing_data.yml',    \n",
    "]\n",
    "\n",
    "# NOTE: please contact the autors for an executable\n",
    "fn_exe = \"p:/11205283-hydromt-floodmodelling/02_models/bin/subgrid_openacc_11_rev295_16092021/sfincs.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_root = join(model_root, \"00_base_100m\")\n",
    "logger = setuplog('update', join(base_root, \"hydromt.log\"), log_level=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model base layers\n",
    "region = {'bbox': [34.33,-20.12,34.95,-19.30]}\n",
    "res = 100 # resolution [m]\n",
    "opt = configread('build_sfincs.ini', abs_path=True)\n",
    "kwargs = opt.pop('global',{})\n",
    "mod = SfincsModel(root=base_root, data_libs=data_libs, logger=logger, **kwargs)\n",
    "mod.build(region=region, res=res, opt=opt)\n",
    "mod.plot_basemap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update base model river bathymetry\n",
    "base_root = join(model_root, \"00_base_100m\")\n",
    "runs = [\n",
    "    (1, {'rivdph_method': 'powlaw'}, {}),\n",
    "    (2, {'rivdph_method': 'powlaw', 'hc': 0.405}, {}),  # 1.5x river depth\n",
    "    (2, {'rivdph_method': 'powlaw', 'hc': 0.135}, {}),   # 0.5x river depth\n",
    "    (3, {'rivdph_method': 'powlaw'}, {'lnd_man': 0.15}),  # 1.5x land manning\n",
    "    (3, {'rivdph_method': 'powlaw'}, {'lnd_man': 0.05}),  # 0.5x land manning\n",
    "]\n",
    "# base_root = join(model_root, \"10_base_50m\")\n",
    "# runs = [\n",
    "#     (11, {'rivdph_method': 'powlaw'}),\n",
    "#     (12, {'rivdph_method': 'manning'}),\n",
    "#     (13, {'rivdph_method': 'gvf'}),\n",
    "#     (18, {'rivdph_method': 'powlaw', 'river_upa': 25}),\n",
    "# ]\n",
    "for i, kwargs, kwargs1 in runs:\n",
    "    opt = configread(f'update_rivbathy.ini', abs_path=True)\n",
    "    postfix = '_'.join([f'{k[:3]}{v}' for k,v in kwargs.items()])\n",
    "    root = join(model_root, f'{i:02d}_{postfix}')\n",
    "    if kwargs1:\n",
    "        postfix1 = '_'.join([f'{k[:3]}{v}' for k,v in kwargs1.items()])\n",
    "        root = f'{root}_{postfix1}'\n",
    "    if isfile(join(root, 'sfincs.inp')):\n",
    "        continue\n",
    "    mod1 = SfincsModel(base_root, mode='r', data_libs=data_libs, logger=logger)\n",
    "    # update bathymetry with specific settings\n",
    "    opt['setup_river_bathymetry'].update(kwargs)\n",
    "    opt['setup_manning_roughness'].update(kwargs1)\n",
    "    mod1.update(model_out=root, opt=opt, write=False)\n",
    "    # set zs ini restart file\n",
    "    mask = np.logical_or(mod1.staticmaps['rivmsk']==1, mod1.staticmaps['dep']<0)\n",
    "    zsini = mod1.staticmaps['dep'].where(~mask, np.maximum(mod1.staticmaps['dep']+0.2, 0.5)).where(mod1.mask!=0,0)\n",
    "    zsini.raster.set_nodata(0)\n",
    "    mod1.set_states(zsini, 'zsini')\n",
    "    mod1.config.pop('zsini',None)\n",
    "    # write static maps, states and config\n",
    "    mod1.write()\n",
    "    mod1.plot_basemap(geoms=[])\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write forcing for idai / eloise\n",
    "runs = [r for r in glob.glob(f'{model_root}/*_rivpowlaw_*') if not isfile(r)]\n",
    "for root0 in runs:\n",
    "    # update forcing in subfolders\n",
    "    for event in ['idai', 'eloise']:\n",
    "        root = join(root0, event)\n",
    "        if isfile(join(root, 'sfincs.inp')):\n",
    "            continue\n",
    "        mod1 = SfincsModel(root0, mode='r', data_libs=data_libs, logger=logger)\n",
    "        opt = configread(f'update_sfincs_{event}.ini', abs_path=True)\n",
    "        mod1.update(model_out=root, opt=opt, write=False)\n",
    "        # write forcing and sfincs.inp only\n",
    "        mod1.write_forcing()\n",
    "        mod1.write_config(rel_path=f'../')\n",
    "        mod1.plot_forcing()\n",
    "        plt.close('all')\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write forcing for sensitivity analysis\n",
    "runs = [r for r in glob.glob(f'{model_root}/*') if not isfile(r)]\n",
    "base_root = join(model_root, \"01_rivpowlaw\")\n",
    "\n",
    "# update forcing in subfolders\n",
    "for event in ['idai', 'eloise']:\n",
    "    for run in ['glofas', 'h_x80', 'h_x120', 'qp_x80', 'qp_x120']:\n",
    "        root = join(base_root, f'{event}_{run}')\n",
    "        if isfile(join(root, 'sfincs.inp')):\n",
    "            continue\n",
    "        mod1 = SfincsModel(base_root, mode='r', data_libs=data_libs, logger=logger)\n",
    "        opt = configread(f'update_sfincs_{event}.ini', abs_path=True)\n",
    "        # glofas forcing only with default 01_ run\n",
    "        if 'glofas' in run:\n",
    "            opt['setup_q_forcing_from_grid'].update({\n",
    "                'discharge_fn': 'glofas_era5', 'uparea_fn': 'glofas_uparea'\n",
    "            })\n",
    "        elif 'qp_' in run:\n",
    "            mult = run.split('_')[1]\n",
    "            dis_fn = opt['setup_q_forcing_from_grid']['discharge_fn']\n",
    "            opt['setup_q_forcing_from_grid'].update({'discharge_fn': f'{dis_fn}_{mult}'})\n",
    "            prec_fn = opt['setup_p_forcing_from_grid']['precip_fn']\n",
    "            opt['setup_p_forcing_from_grid'].update({'precip_fn': f'{prec_fn}_{mult}'})\n",
    "        elif 'h_' in run:\n",
    "            mult = run.split('_')[1]\n",
    "            h_fn = opt['setup_h_forcing']['geodataset_fn']\n",
    "            opt['setup_h_forcing'].update({'geodataset_fn': f'{h_fn}_{mult}'})\n",
    "        mod1.update(model_out=root, opt=opt, write=False)\n",
    "        # write forcing and sfincs.inp only\n",
    "        mod1.write_forcing()\n",
    "        mod1.write_config(rel_path=f'../')\n",
    "        mod1.plot_forcing()\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydromt_sfincs.utils import write_timeseries, write_inp\n",
    "import os\n",
    "## prepare compound runs\n",
    "\n",
    "base_root = join(model_root, \"01_rivpowlaw\")\n",
    "base_root = join(model_root, \"02_rivpowlaw_hc0.405\")\n",
    "for event in ['idai', 'eloise']:\n",
    "    mod = SfincsModel(join(base_root, event), mode='r', data_libs=data_libs)\n",
    "    config = mod.config.copy()\n",
    "    tref = config['tref']\n",
    "\n",
    "    # get htide\n",
    "    htot = mod.forcing['bzs'].copy()\n",
    "    mod.setup_h_forcing(\n",
    "        geodataset_fn = f'gtsm_{event}_tides',   # waterlevel timeseries dataset\n",
    "    )\n",
    "    htide = mod.forcing['bzs'].copy()\n",
    "    assert np.all(htide.vector.xcoords.round(0) == htot.vector.xcoords.round(0))\n",
    "    assert np.all(htide.vector.ycoords.round(0) == htot.vector.ycoords.round(0))\n",
    "\n",
    "    da_dis = mod.forcing['dis'].copy()\n",
    "    # get discharge climatology\n",
    "    # NOTE: requires long series which is not added to the repos; use hardcoded values here\n",
    "    # mod.setup_config(**{\n",
    "    #     'tref': '19900101 000000',\n",
    "    #     'tstart': '19900101 000000',\n",
    "    #     'tstop': '20201231 000000',\n",
    "    # })\n",
    "    # mod.setup_q_forcing_from_grid(\n",
    "    #     discharge_fn = 'cmf_outflw_06min',   # TODO change to 3min version\n",
    "    #     uparea_fn = 'cmf_uparea_06min',   \n",
    "    # )\n",
    "    # da_dis_long = mod.forcing['dis'].copy()\n",
    "    # qmean = da_dis_long.groupby('time.quarter').mean().sel(quarter=int(np.mean(da_dis.time.dt.quarter)))\n",
    "    # qmean = da_dis_long.groupby('time.month').mean().sel(month=int(np.mean(da_dis.time.dt.month)))\n",
    "    # qmean = da_dis_long.mean('time')\n",
    "    # print(qmean.values)\n",
    "    qmean = xr.DataArray(dims='index', data=np.array([161.7727,0.7046502,0.44472486,4.4982467,3.2484558,96.676094,20.92196], dtype=np.float32), )\n",
    "    fact = np.minimum(1,qmean/da_dis.mean())\n",
    "    print(fact.values)\n",
    "    da_disclim = da_dis*fact\n",
    "\n",
    "    qs = {\n",
    "        'disclim': da_disclim.reset_coords(drop=True).to_series().unstack(0),\n",
    "        'dis': da_dis.reset_coords(drop=True).to_series().unstack(0), \n",
    "    }\n",
    "    hs = {\n",
    "        'htide': htide.reset_coords(drop=True).to_series().unstack(0),\n",
    "        'htot': htot.reset_coords(drop=True).to_series().unstack(0),\n",
    "    }\n",
    "    ps = {\n",
    "        'noprecip': None,\n",
    "        'precip': mod.forcing['netampr'].copy(),\n",
    "    }\n",
    "    cmpd_runs = {\n",
    "        'q': ['dis', 'htide', 'noprecip'],\n",
    "        'h': ['disclim', 'htot', 'noprecip'],\n",
    "        'p': ['disclim', 'htide', 'precip'],\n",
    "        # 'base': ['disclim', 'htide', 'noprecip'],\n",
    "        # 'qh': ['dis', 'htot', 'noprecip'],\n",
    "        }\n",
    "    for run, (q, h, p) in cmpd_runs.items():\n",
    "        root = join(base_root, f'{event}_{run}')\n",
    "        if not os.path.isdir(root):\n",
    "            os.makedirs(root)\n",
    "        else:\n",
    "            continue\n",
    "        print(f'{event}_{run}')\n",
    "\n",
    "        shutil.copyfile(join(base_root, event, 'sfincs.src'), join(root, 'sfincs.src'))\n",
    "        write_timeseries(join(root, 'sfincs.dis'), qs[q], tref)\n",
    "        shutil.copyfile(join(base_root, event, 'sfincs.bnd'), join(root, 'sfincs.bnd'))\n",
    "        write_timeseries(join(root, 'sfincs.bzs'), hs[h], tref)\n",
    "        \n",
    "        config1 = config.copy()\n",
    "        if ps[p] is None:\n",
    "            config1.pop('netamprfile')\n",
    "        else:\n",
    "            try:\n",
    "                ps[p].to_netcdf(join(root, 'precip.nc'))\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        write_inp(join(root, 'sfincs.inp'), config1)\n",
    "\n",
    "        mod1 = SfincsModel(root, mode='r')\n",
    "        mod1.plot_forcing()\n",
    "        plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run models\n",
    "from os.path import dirname\n",
    "\n",
    "def check_finished(root):\n",
    "    finished = False\n",
    "    if isfile(join(root, 'sfincs.log')):\n",
    "        with open(join(root, 'sfincs.log'), 'r') as f:\n",
    "            finished = np.any(['Simulation is finished' in l for l in f.readlines()])\n",
    "    return finished\n",
    "\n",
    "runs = [dirname(fn) for fn in glob.glob(join(model_root, '*', '*', 'sfincs.inp')) if not check_finished(dirname(fn))]\n",
    "n = len(runs)\n",
    "print(n)\n",
    "for i, root in enumerate(runs):\n",
    "    print(f'{i+1:d}/{n:d}: {root}')\n",
    "    with open(join(root, \"sfincs.log\"), 'w') as f:\n",
    "        p = subprocess.Popen([fn_exe], stdout=f, cwd=root)\n",
    "        %time p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('compound_hazard')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1fb41f7d3c9d44edbd7f9d2eb0da8e67c67759afdf54e6c06938bd0d90c16cc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
