{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccafd318",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydromt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join, basename\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import pygeos\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de90faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox =  32.0, -21.5, 35.5, -17.0\n",
    "cat = hydromt.DataCatalog(deltares_data=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read AVISO MDT\n",
    "\n",
    "da_mdt = cat.get_rasterdataset('mdt_cnes_cls18', bbox=bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b3ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODEC\n",
    "root = r'p:\\11205283-hydromt-floodmodelling\\00_data'\n",
    "chunks={'stations': 100, 'time':-1}\n",
    "rm = {'station_x_coordinate':'lon', 'station_y_coordinate':'lat'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80a6253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'CODEC'\n",
    "# fns = glob.glob(join(root, name, 'reanalysis_waterlevel_10min_*_v1_beira.nc'))\n",
    "# ds_gtsm0 = xr.open_dataset(fns[0], chunks=chunks).rename(rm).vector.clip_bbox(bbox)\n",
    "# gdf_gtsm = ds_gtsm0.vector.to_gdf().set_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fddd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "## IDAI / ELOISE\n",
    "events = {\n",
    "    # 'idai': dict(\n",
    "    #     name = 'GTSM_20190218_20190401_IDAI',\n",
    "    #     dates = ('2019-01-01', '2019-05-01')\n",
    "    # ),\n",
    "    'eloise': dict(\n",
    "        name = 'GTSM_20201218_20210201_ELOISE',\n",
    "        dates = ('2021-01-01', '2021-03-01')\n",
    "    \n",
    "    )\n",
    "}\n",
    "var = 'waterlevel'\n",
    "encoding = {var: {'dtype': 'float32'}}\n",
    "runs = ['era5', 'spw', 'tides', 'era5_tides', 'spw_tides', 'era5_spw_tides'][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e56c034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select stations within bbox\n",
    "prefix = next(iter(events))\n",
    "fn0 = join(root, events[prefix]['name'], f'{prefix}_{runs[0]}_his.nc')\n",
    "da_gtsm0 = xr.open_dataset(fn0, chunks=chunks).rename(rm)[var]\n",
    "da_gtsm0['stations'] = da_gtsm0.stations\n",
    "da_gtsm0 = da_gtsm0.vector.clip_bbox(bbox)\n",
    "da_gtsm0.raster.set_crs(4326)\n",
    "gdf_gtsm = da_gtsm0.vector.to_gdf()\n",
    "gdf_gtsm.to_file(join(root, 'gtsm_beira.geojson'), driver='GeoJSON')\n",
    "da_gtsm0.station_name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a61c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "mdt0 = da_mdt.raster.sample(gdf_gtsm).rename({'index': 'stations'}).reset_coords(drop=True)\n",
    "mdt0.name = 'mdt'\n",
    "run = ''\n",
    "\n",
    "for prefix, event in events.items():\n",
    "    print(event)\n",
    "    name = event['name']\n",
    "    tstart, tstop = event['dates']\n",
    "    # reindex to get timeseries from JAN-01\n",
    "    time = xr.IndexVariable('time', pd.date_range(tstart, tstop, freq='10MIN'))\n",
    "\n",
    "    # read htot\n",
    "    fn_htot = join(root, name, f'{prefix}_era5_spw_tides_his.nc')\n",
    "    da_htot = xr.open_dataset(fn_htot, chunks=chunks)[var].sel(stations=gdf_gtsm.index)\n",
    "    da_htot = da_htot.resample(time='10MIN').nearest().reindex(time=time, fill_value=0)\n",
    "    # read htide\n",
    "    fn_htide = join(root, name, f'{prefix}_tides_his.nc')\n",
    "    da_htide = xr.open_dataset(fn_htide, chunks=chunks)[var].sel(stations=gdf_gtsm.index)\n",
    "    da_htide = da_htide.resample(time='10MIN').nearest().reindex(time=time, fill_value=0)\n",
    "    # read waves\n",
    "    da_shww0 = cat.get_rasterdataset('era5_hourly', bbox=bbox, variables=['shww'], time_tuple=(tstart, tstop))\n",
    "    da_shww = da_shww0.raster.sample(gdf_gtsm).rename({'index': 'stations'}).reset_coords(drop=True)\n",
    "    da_shww = da_shww.reindex(time=time, method='nearest').load()\n",
    "    da_shww.name = 'shww'\n",
    "    \n",
    "    # combine sl components\n",
    "    # write htot referenced to EGM\n",
    "    da_htot1 = mdt0 + da_htot + da_shww*0.2\n",
    "    da_htot1.name = var\n",
    "    da_surge1 = da_htot - da_htide\n",
    "    da_surge1.name = 'surge'\n",
    "    da_htide.name = 'tide'\n",
    "    fn_out = fn_htot.replace('.nc', '_beira_egm.nc')\n",
    "    ds_out = xr.merge([da_htot1, da_htide, da_surge1, da_shww, mdt0]).transpose('time','stations')\n",
    "    encoding1 = {v: {'zlib': True} for v in ds_out.data_vars}\n",
    "    print(basename(fn_out))\n",
    "    ds_out.to_netcdf(fn_out, encoding=encoding1)\n",
    "\n",
    "    # write htide referenced to EGM\n",
    "    da_htide1 = mdt0 + da_htide\n",
    "    da_htide1.name = var\n",
    "    da_htide1 = da_htide1.transpose('time','stations')\n",
    "    fn_out = fn_htide.replace('.nc', '_beira_egm.nc')\n",
    "    print(basename(fn_out))\n",
    "    da_htide1.to_netcdf(fn_out, encoding=encoding)\n",
    "    \n",
    "    # sensitivity analysis on surge + waves\n",
    "    for mult in [0.8, 1.2]:  # sensitivity\n",
    "        da_htot2 = mdt0 + (da_htot + da_shww*0.2)*mult\n",
    "        da_htot2.name = var\n",
    "        da_htot2 = da_htot2.transpose('time','stations')\n",
    "        fn_out1 = fn_htot.replace('.nc', f'_beira_egm_x{int(mult*100)}.nc')\n",
    "        print(basename(fn_out1))\n",
    "        da_htot2.to_netcdf(fn_out1, encoding=encoding)      \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab2e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydromt\n",
    "\n",
    "events = {'idai': ('20190314', '20190316'), 'eloise':('20210122', '20210124')}\n",
    "event ='eloise'\n",
    "fn = f'../../1_data/2_forcing/GTSM/{event}_era5_spw_tides_his_beira_egm.nc'\n",
    "ds = xr.open_dataset(fn).sel(time=slice(*events[event])).dropna('stations')\n",
    "ds.vector.set_spatial_dims(x_dim='station_x_coordinate', y_dim='station_y_coordinate', index_dim='stations')\n",
    "itime = ds['waterlevel'].argmax('time')\n",
    "# ds.isel(time=itime).vector.to_gdf().drop(columns=['station_name', 'time']).to_file(fn.replace('.nc', '.geojson'), driver='GeoJSON')\n",
    "ds['shww'] = ds['shww']*0.2\n",
    "ds['waterlevel'] = ds['waterlevel'] - ds['mdt']\n",
    "ds0 = ds.isel(time=itime).sel(stations=[17492, 17493, 18275, 18276])\n",
    "(ds0['shww'] / (ds0['tide'] + ds0['surge'] + ds0['shww'])).mean()\n",
    "ds0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fe4646",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(stations=[17492, 17493, 18275, 18276]).max('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce81b850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
