{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydromt_sfincs import SfincsModel\n",
    "from os.path import join, isfile, basename, isdir, dirname\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import hydromt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = {'idai': ['20190319', '20190320'], 'eloise':['20210125','20210126']}\n",
    "tslice_max = {'idai': ('20190313', '20190321'), 'eloise':('20210120', '20210127')}\n",
    "root0 = r'../../3_models/SFINCS2'\n",
    "mod0 = SfincsModel(join(root0, '00_base_100m'), mode='r')\n",
    "\n",
    "def check_finished(root):\n",
    "    finished = False\n",
    "    if isfile(join(root, 'sfincs.log')):\n",
    "        with open(join(root, 'sfincs.log'), 'r') as f:\n",
    "            finished = np.any(['Simulation is finished' in l for l in f.readlines()])\n",
    "    return finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and combine SFINCS outputs\n",
    "postfix, i = '_100m', 0\n",
    "runs = glob.glob(join(root0, '*/*/','sfincs_map.nc'))\n",
    "encoding = {'flddph': {'zlib': True}}\n",
    "\n",
    "# mod0 = SfincsModel(runs[0], mode='r')\n",
    "# print(runs)\n",
    "\n",
    "for event, dates in events.items():\n",
    "    runs = glob.glob(join(root0, '0*', f'{event}*', 'sfincs_map.nc'))\n",
    "    print(event)\n",
    "    da_lst, da_lst1, names = [], [], []\n",
    "    for run in runs:\n",
    "        root = dirname(run)\n",
    "        if not basename(dirname(root)).startswith(str(i)): continue\n",
    "        if not check_finished(root): \n",
    "            print(f'{root} NOT FINISHED / FAILED')\n",
    "            continue\n",
    "        mod = SfincsModel(root, mode='r')\n",
    "        key = basename(root).strip(f'{event}')\n",
    "        name = f'{basename(dirname(root))}{key}'\n",
    "        # print(name)\n",
    "        mod.read_results()\n",
    "        hmax = np.maximum(0, mod.results['zsmax'] - mod.results['zb'])\n",
    "        hmax = hmax.fillna(0).where(mod.results['zb'].notnull(),-9999)\n",
    "        hmax.raster.set_nodata(-9999)\n",
    "        # hmax = hmax.raster.reproject_like(mod0.staticmaps, 'min')\n",
    "        # save geotif\n",
    "        # hmax.raster.flipud().raster.to_raster(join(mod.root, 'gis', 'hmax.tif'), compress='lzw')\n",
    "        # append to list\n",
    "        da_lst.append(hmax.sel(timemax=slice(*tslice_max[event])).rename({'timemax': 'time'}).rename('flddph'))\n",
    "        # da_lst.append(hmax.sel(timemax=dates).rename({'timemax': 'time'}).rename('flddph'))\n",
    "        # da_lst1.append(hmax.sel(timemax=slice(*tslice_max[event])).max('timemax').rename('flddph'))\n",
    "        names.append(name)\n",
    "    # save combined output to nc\n",
    "    da = xr.concat(da_lst, dim='run')\n",
    "    da['run'] = xr.IndexVariable('run', names)\n",
    "    da.to_netcdf(join(root0, f'flddph_{event}{postfix}_v2.nc'), encoding=encoding)\n",
    "    # save combined output to nc\n",
    "    # da = xr.concat(da_lst1, dim='run')\n",
    "    # da['run'] = xr.IndexVariable('run', names)\n",
    "    # da.to_netcdf(join(root0, f'flddph_{event}{postfix}_max_v2.nc'), encoding=encoding)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and combine CMF outputs\n",
    "import pandas as pd\n",
    "root = r'../../3_models/CMF'\n",
    "encoding = {'flddph': {'zlib': True}}\n",
    "\n",
    "for event, _ in events.items():\n",
    "    da_lst, names = [], []\n",
    "    dates = pd.date_range(*tslice_max[event], freq='D').strftime('%Y%m%d')\n",
    "    for res in ['03min', '06min']:\n",
    "        runs = [path for path in glob.glob(join(root, res, '0*')) if isdir(path)]\n",
    "        for run in runs:\n",
    "            da_lst0 = []\n",
    "            for date in dates:\n",
    "                fn = join(run, f'flddph_{date}.tif')\n",
    "                if not isfile(fn): \n",
    "                    print('missing', fn)\n",
    "                    continue\n",
    "                hmax = hydromt.open_raster(fn).raster.reproject_like(mod0.staticmaps)\n",
    "                da_lst0.append(hmax.rename('flddph'))\n",
    "            da0 = xr.concat(da_lst0, dim='time')\n",
    "            da0['time'] = xr.IndexVariable('time', pd.to_datetime(dates))\n",
    "            da_lst.append(da0)\n",
    "            names.append(f'{basename(run)}_{res}')\n",
    "    # save combined output to nc\n",
    "    print(names)\n",
    "    da = xr.concat(da_lst, dim='run')\n",
    "    da['run'] = xr.IndexVariable('run', names)\n",
    "    da.to_netcdf(join(root, f'flddph_{event}_v2.nc'), encoding=encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('compound_hazard2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ff157b875d130708b62c1a0894fbc6ff6f8e6586fc48c3b625ee942e47421840"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
