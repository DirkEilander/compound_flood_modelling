{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1240cf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import hydromt\n",
    "from os.path import join, basename, dirname\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from hydromt.models import SfincsModel\n",
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a9326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydromt_sfincs.workflows import burn_bathymetry, get_river_bathymetry, get_estuary_bathymetry\n",
    "from hydromt_sfincs.utils import write_binary_map, write_inp\n",
    "from hydromt_sfincs.gis_utils import flipud\n",
    "import pyflwdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9be7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_exe = \"p:/11205283-hydromt-floodmodelling/02_models/bin/subgrid_openacc_11_rev295_16092021/sfincs.exe\"\n",
    "mdir = r\"../02_models/beira/sfincs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe75232",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod00 = SfincsModel(join(mdir, '00_base'), mode='r')\n",
    "mod00.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod01 = SfincsModel(join(mdir, '01_base_full'), mode='r', deltares_data=True, data_libs=join(mdir, 'data_sources.yml'))\n",
    "mod01.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5991f",
   "metadata": {},
   "source": [
    "## create restart file run with average conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "q = xr.open_dataarray(join(mdir, 'forcing_data',  'cama_outflw_era5.nc'))\n",
    "qmean = q.mean('time').expand_dims('time').transpose('index', 'time')\n",
    "qmean['time'] = xr.IndexVariable('time', pd.to_datetime(['20200101']))\n",
    "dis = qmean.reindex_like(mod01.forcing['dis'], method='nearest')\n",
    "havg = mod01.forcing['bzs'].mean().expand_dims('time').expand_dims('index')\n",
    "havg['time'] = xr.IndexVariable('time', pd.to_datetime(['20200101']))\n",
    "havg['index'] = xr.IndexVariable('index', [0])\n",
    "havg = havg.reindex_like(mod01.forcing['bzs'], method='nearest')\n",
    "havg['x'] = mod01.forcing['bzs']['x']\n",
    "havg['y'] = mod01.forcing['bzs']['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13216da",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = basename(mod01.root)\n",
    "config = mod01.config.copy()\n",
    "for k, v in config.items():\n",
    "    if k[:-4] in ['dis', 'bzs']:\n",
    "        config.update({k: basename(v)})\n",
    "    elif k.endswith('file') and '01_base_full' not in v:\n",
    "        config.update({k:f'../{root}/{basename(v)}'})\n",
    "config.update({'alpha': 0.7})\n",
    "config.update({'restartfile': 'sfincs.restart'})\n",
    "tref = config['tref']\n",
    "\n",
    "# no precip\n",
    "_ = config.pop('netampr', None)\n",
    "_ = mod01.forcing.pop('netampr', None)\n",
    "\n",
    "# mean dis, bzs\n",
    "mod01.set_forcing(dis, name='dis')\n",
    "mod01.set_forcing(havg, name='bzs')\n",
    "\n",
    "mod01.set_root(join(mdir, '01_base_full_mean'), mode='w')\n",
    "mod01.config.update(**config)\n",
    "mod01.write_forcing()\n",
    "mod01.write_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d71d0",
   "metadata": {},
   "source": [
    "## rivdph runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583bbf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "river_upa = 25\n",
    "\n",
    "da_msk0 = mod01.staticmaps['msk'].copy()\n",
    "# da_scs0 = mod01.staticmaps['scs'].copy()\n",
    "\n",
    "ds_mod0 = flipud(mod00.staticmaps)\n",
    "ds_mod1 = flipud(mod01.staticmaps)\n",
    "da_elv0 = ds_mod0['dep'].copy()\n",
    "da_upa0 = ds_mod1[\"uparea\"].copy()\n",
    "da_flw0 = ds_mod1[\"flwdir\"].copy()\n",
    "\n",
    "rivd8 = da_upa0 > river_upa\n",
    "flwdir = hydromt.flw.flwdir_from_da(da_flw0, mask=rivd8)\n",
    "\n",
    "# geoms\n",
    "gdf_stream = mod01.staticgeoms['rivers'].copy()\n",
    "# flw = pyflwdir.from_dataframe(gdf_stream.set_index(\"idx\"))\n",
    "# flw.main_upstream(gdf_stream[\"uparea\"].values)\n",
    "# rivqbf = np.maximum(0, gdf_stream[\"qbankfull\"].fillna(0))\n",
    "# estuary = gdf_stream[\"estuary\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde1c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "da_rivmask = mod01.data_catalog.get_rasterdataset('grwl_mask', geom=mod01.region, buffer=10)\n",
    "_mask_dst = da_elv0.raster.reproject_like(da_rivmask) != da_elv0.raster.nodata\n",
    "da_rivmask = da_rivmask.where(_mask_dst, 0) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "hmin=1.0\n",
    "\n",
    "root = basename(mod01.root)\n",
    "config = mod01.config.copy()\n",
    "for k, v in config.items():\n",
    "    if k.startswith('dep'):\n",
    "        config.update({k:'sfincs.dep'})\n",
    "    elif k.endswith('file') and not '01_base_full' in v:\n",
    "        config.update({k:f'../{root}/{basename(v)}'})\n",
    "config.update({'dtout': 86400})\n",
    "config.update({'alpha': 0.7})\n",
    "\n",
    "hps = np.arange(0.25, 0.41, 0.05)\n",
    "hcs = np.arange(0.25, 0.41, 0.05)\n",
    "# hcs=[0.27]\n",
    "# hps=[0.30]\n",
    "\n",
    "irun = 10\n",
    "for hc, hp in zip(hcs, hps):\n",
    "# for hc, hp in zip([0.35], [0.30]):\n",
    "    irun += 1\n",
    "    gdf_stream = mod01.staticgeoms['rivers'].copy().drop(columns=['rivdph'])\n",
    "    gdf_stream = get_river_bathymetry(gdf_stream, hc=hc, hp=hp)\n",
    "    da_estuary=None\n",
    "    gdf_stream, da_estuary = get_estuary_bathymetry(gdf_stream, da_rivmask=da_rivmask)\n",
    "    da_elv = burn_bathymetry(gdf_stream, da_elv0, da_rivmask=da_estuary)[0]\n",
    "    da_elv.data = flwdir.dem_dig_d4(da_elv.values)\n",
    "    \n",
    "    davg = gdf_stream['rivdph'].mean()\n",
    "    dmax = gdf_stream['rivdph'].max()\n",
    "\n",
    "    run = f'02_{irun:02d}_hc{hc*100:02.0f}_hp{hp*100:02.0f}_D4'\n",
    "    print(f'{run} mean {davg:.2f} max {dmax:.2f}')\n",
    "    \n",
    "    root = join(mdir, run)\n",
    "    if not os.path.isdir(root):\n",
    "        os.makedirs(root)\n",
    "    write_binary_map(join(root, 'sfincs.dep'), flipud(da_elv).values, da_msk0.values)\n",
    "    write_inp(join(root, 'sfincs.inp'), config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162d721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SfincsModel(join(mdir, run), mode='r')\n",
    "mod.read()\n",
    "mod.plot_basemap(variable='dep', geoms=['bnd', 'src'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0892c3",
   "metadata": {},
   "source": [
    "## scs runs\n",
    "\n",
    "(not used with ERA5 runoff based 'net precip')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed29cadf",
   "metadata": {},
   "source": [
    "config = mod01.config.copy()\n",
    "for k, v in config.items():\n",
    "    if k.endswith('file') and not k.startswith('scs'):\n",
    "        config.update({k:f'../01_base_full/{v}'})\n",
    "config.update({'dtout': 86400})\n",
    "config.update({'alpha': 0.7})\n",
    "\n",
    "scs_prod = [0.5, 1.5, 2.0]\n",
    "irun = 9\n",
    "for prod in scs_prod:\n",
    "    irun += 1\n",
    "    da_scs = da_scs0.where(da_scs0<=0, da_scs0*prod)\n",
    "\n",
    "    run = f'02_{irun:02d}_scs{prod:.1f}'\n",
    "    davg = da_scs.where(da_scs>0).mean().values\n",
    "    dmax = da_scs.where(da_scs>0).max().values\n",
    "    print(f'{run} mean {davg:.2f} max {dmax:.2f}')\n",
    "    root = join(mdir, run)\n",
    "    if not os.path.isdir(root):\n",
    "        os.makedirs(root)\n",
    "    write_binary_map(join(root, 'sfincs.scs'), da_scs.values, da_msk0.values)\n",
    "    write_inp(join(root, 'sfincs.inp'), config)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e10ef8bd",
   "metadata": {},
   "source": [
    "mod = SfincsModel(join(mdir, run), mode='r')\n",
    "mod.read()\n",
    "mod.plot_basemap(variable='scs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1197b20c",
   "metadata": {},
   "source": [
    "## runoff runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d69aab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod01.data_catalog.from_yml(r'../02_models/beira/cmf/out/cama.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9495a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "precip = mod01.forcing['netampr'].copy()\n",
    "_ = mod01.forcing.pop('bzs', None)\n",
    "\n",
    "root = basename(mod01.root)\n",
    "config = mod01.config.copy()\n",
    "for k, v in config.items():\n",
    "    if k.startswith('dis') or k.startswith('netampr'):\n",
    "        config.update({k:basename(v)})\n",
    "    elif k.endswith('file') and not '01_base_full' in v:\n",
    "        config.update({k:f'../{root}/{basename(v)}'})\n",
    "config.update({'dtout': 86400})\n",
    "config.update({'alpha': 0.7})\n",
    "mod01.config.update(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod01.set_root('../02_models/beira/sfincs/02_051_ro080', mode='w')\n",
    "mod01.setup_q_forcing_from_grid(\n",
    "    discharge_fn='cama_outflw080',\n",
    "    uparea_fn='cama_uparea',\n",
    ")\n",
    "mod01.set_forcing(precip*0.8, name='netampr')\n",
    "mod01.write_forcing()\n",
    "mod01.write_config()\n",
    "# mod01.plot_forcing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff03de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod01.set_root('../02_models/beira/sfincs/02_061_ro120', mode='w')\n",
    "mod01.setup_q_forcing_from_grid(\n",
    "    discharge_fn='cama_outflw120',\n",
    "    uparea_fn='cama_uparea',\n",
    ")\n",
    "mod01.set_forcing(precip*1.2, name='netampr')\n",
    "mod01.write_forcing()\n",
    "mod01.write_config()\n",
    "# mod01.plot_forcing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279e2b89",
   "metadata": {},
   "source": [
    "## compound runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5fdf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get htide\n",
    "mod01.setup_h_forcing(\n",
    "    geodataset_fn = 'idai_tides_his_beira_egm',   # waterlevel timeseries dataset\n",
    "    buffer = 1000\n",
    ")\n",
    "mod01.forcing['bzs'].attrs.pop('category', None)\n",
    "mod01.forcing['bzs'].reset_coords(drop=True).to_netcdf(join(mdir, 'forcing_data', 'htide_idai.nc'))\n",
    "\n",
    "### RE-INITIALIZE mod01 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e699ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get qmean\n",
    "# mod01.setup_config(**dict(\n",
    "#     tref = '19800101 000000',\n",
    "#     tstart = '19800101 000000',\n",
    "#     tstop = '20191231 000000',\n",
    "# ))\n",
    "# mod01.setup_q_forcing_from_grid(\n",
    "#     discharge_fn = 'cama_outflw',\n",
    "#     uparea_fn = 'cama_uparea',\n",
    "#     rel_error = 0.05,\n",
    "#     abs_error = 100\n",
    "# )\n",
    "# mod01.forcing['dis'].load()\n",
    "# mod01.forcing['dis'].to_netcdf(join(mdir, 'forcing_data',  'cama_outflw_era5.nc'))\n",
    "# mod01.read()\n",
    "qts = mod01.forcing['dis'].copy()\n",
    "q = xr.open_dataarray(join(mdir, 'forcing_data',  'cama_outflw_era5.nc'))\n",
    "qmean = q.groupby('time.month').mean().sel(month=int(np.mean(qts.time.dt.month)))\n",
    "fact = np.minimum(1,qmean/qts.mean())\n",
    "print(fact.values)\n",
    "da_disclim = qts*fact\n",
    "\n",
    "htide = xr.open_dataarray(join(mdir, 'forcing_data',  'htide_eloise.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f8221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from hydromt_sfincs.utils import write_timeseries\n",
    "\n",
    "root = basename(mod01.root)\n",
    "config = mod01.config.copy()\n",
    "for k, v in config.items():\n",
    "    if k[:-4] in ['dis', 'bzs', 'netampr']:\n",
    "        config.update({k: basename(v)})\n",
    "    elif k.endswith('file') and '01_base_full' not in v:\n",
    "        config.update({k:f'../{root}/{basename(v)}'})\n",
    "config.update({'alpha': 0.7})\n",
    "tref = config['tref']\n",
    "\n",
    "qs = {\n",
    "    'dis': mod01.forcing['dis'].to_series().unstack(0), \n",
    "    'disclim': da_disclim.to_series().unstack(0)\n",
    "}\n",
    "hs = {\n",
    "    'htot': mod01.forcing['bzs'].to_series().unstack(0),\n",
    "    'htide': htide.to_series().unstack(0),\n",
    "}\n",
    "ps = {\n",
    "    'precip': mod01.forcing['netampr'].copy(),\n",
    "#     'runoff': \n",
    "    'noprecip': None\n",
    "}\n",
    "\n",
    "irun = 10\n",
    "# combis = [\n",
    "#     ('dis', 'htot', 'precip'), \n",
    "#     ('dis', 'htide', 'noprecip'),\n",
    "#     ('disclim', 'htot', 'noprecip'),\n",
    "#     ('disclim', 'htide', 'precip'),\n",
    "# ]:\n",
    "\n",
    "for q, h, p in product(qs.keys(), hs.keys(), ps.keys()):\n",
    "    irun += 1\n",
    "    \n",
    "    config1 = config.copy()\n",
    "    \n",
    "    run = f'03_{irun:02d}_{h}_{q}_{p}'\n",
    "    root = join(mdir, run)\n",
    "    if not os.path.isdir(root):\n",
    "        os.makedirs(root)\n",
    "\n",
    "    write_timeseries(join(root, 'sfincs.dis'), qs[q], tref)\n",
    "    write_timeseries(join(root, 'sfincs.bzs'), hs[h], tref)\n",
    "    if ps[p] is None:\n",
    "        config1.pop('netamprfile')\n",
    "    else:\n",
    "        ps[p].to_netcdf(join(root, 'precip.nc'))\n",
    "        \n",
    "    write_inp(join(root, 'sfincs.inp'), config1)\n",
    "    \n",
    "#     mod = SfincsModel(join(mdir, run), mode='r')\n",
    "#     mod.plot_forcing()\n",
    "#     plt.close()\n",
    "#     if 'precip' in mod.forcing:\n",
    "#         mod.forcing['precip'].close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a9f188",
   "metadata": {},
   "source": [
    "## do runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbd1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from os.path import join, basename\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "runs = glob.glob(join(mdir, '02_*'))# + glob.glob(join(mdir, '03_*'))\n",
    "# runs = glob.glob(join(mdir, '01_*mean*'))\n",
    "len(runs), runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c551471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "for root in runs:\n",
    "#     if os.path.isfile(os.path.join(root, 'sfincs_map.nc')):\n",
    "#         continue\n",
    "    print(os.path.basename(root))\n",
    "    with open(os.path.join(root, \"sfincs.log\"), 'w') as f:\n",
    "        p = subprocess.Popen([fn_exe], stdout=f, cwd=root)\n",
    "        p.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd1b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
