{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import hydromt\n",
    "from os.path import join, basename, isfile\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from hydromt_sfincs import SfincsModel\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skill(da_sim, da_obs, da_msk, hmin=0.15):\n",
    "    sim = da_sim>hmin\n",
    "    obs = da_obs>0  # assume obs is binary mask of extent\n",
    "\n",
    "    ds = xr.Dataset(dict(\n",
    "        true_pos = np.logical_and(sim, obs),\n",
    "        false_neg = np.logical_and(~sim, obs),\n",
    "        false_pos = np.logical_and(sim, ~obs),\n",
    "    )).where(~da_msk,False)\n",
    "    \n",
    "    ntot = np.logical_or(sim, obs).where(~da_msk,False).sum(('x', 'y'))\n",
    "    nobs = obs.where(~da_msk,False).sum(('x', 'y'))\n",
    "    nsim = sim.where(~da_msk,False).sum(('x', 'y'))\n",
    "    \n",
    "    hit_rate = ds['true_pos'].sum(('x', 'y')) / nobs\n",
    "    false_rate = ds['false_pos'].sum(('x', 'y')) / nsim\n",
    "    csi = ds['true_pos'].sum(('x', 'y')) / ntot\n",
    "    bias = ds['false_pos'].sum(('x', 'y')) / ds['false_neg'].sum(('x', 'y'))\n",
    "    da_skill = xr.merge([csi.rename('C'), hit_rate.rename('H'), false_rate.rename('F'), bias.rename('E')])\n",
    "    \n",
    "    # true negative and mask are both 0\n",
    "    da_cm = (ds['true_pos']*3+ds['false_pos']*2+ds['false_neg']*1).astype(np.uint8)\n",
    "    da_cm.raster.set_crs(da_sim.raster.crs)\n",
    "    da_cm.raster.set_nodata(da_sim.raster.crs)\n",
    "        \n",
    "    return da_skill, da_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod0 = SfincsModel('../02_models/beira/sfincs/03_01_htot_dis_precip', mode='r', deltares_data=True)\n",
    "mod1 = SfincsModel('../02_models/beira/sfincs/03_07_htide_disclim_precip', mode='r', deltares_data=True)\n",
    "trange = slice('20190313T0000','20190324T0000')\n",
    "event = 'idai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1.forcing['bzs'].max('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax, ax1) = plt.subplots(2,1, figsize=(15,10))\n",
    "# (mod0.forcing['bzs']-mod1.forcing['bzs']).plot.line(x='time', ax=ax)\n",
    "\n",
    "tslice = slice('20190318', '20190321')\n",
    "mod0.forcing['dis'].isel(index=3).sel(time=tslice).plot.line(x='time', ax=ax1)\n",
    "mod0.forcing['bzs'].isel(index=1).sel(time=tslice).plot.line(x='time', ax=ax, label='total')\n",
    "mod1.forcing['bzs'].isel(index=1).sel(time=tslice).plot.line(x='time', ax=ax, label='tide')\n",
    "ax.legend()\n",
    "print((mod0.forcing['bzs']-mod1.forcing['bzs']).isel(index=1).sel(time=tslice).min('time'))\n",
    "# ax.set_ylim([3.5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grwl_mask = mod0.data_catalog.get_rasterdataset('grwl_mask', geom=mod0.region, buffer=10).raster.reproject_like(mod0.staticmaps)\n",
    "riv_mask = np.logical_or(mod0.staticmaps['rivmsk']>0, grwl_mask>0)\n",
    "dep_mask = mod0.staticmaps['dep']==-9999\n",
    "da_mask = np.logical_or(dep_mask, riv_mask)\n",
    "# riv_mask.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod0 = SfincsModel('../02_models/beira/sfincs/03_11_htot_dis_precip', mode='r', deltares_data=True)\n",
    "mod1 = SfincsModel('../02_models/beira/sfincs/03_17_htide_disclim_precip', mode='r', deltares_data=True)\n",
    "trange = slice('20210118T0000','20210128T0000')\n",
    "event = 'eloise'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod0.read_config()\n",
    "# mod0.read_forcing()\n",
    "# geom_style = {\n",
    "#     \"msk2\": dict(linestyle=\"-\", linewidth=3, color=\"y\"),\n",
    "#     \"msk3\": dict(linestyle=\"-\", linewidth=3, color=\"orangered\"),\n",
    "# }\n",
    "# mod0.plot_basemap(geoms=['bnd', 'src'], geom_kwargs=geom_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "forcing = mod0.forcing\n",
    "kwargs=dict()\n",
    "\n",
    "colors = ['#377eb8', '#ff7f00', '#4daf4a', '#f781bf', '#a65628', '#984ea3', '#999999', '#e41a1c', '#dede00']\n",
    "\n",
    "n = len(forcing.keys())\n",
    "kwargs0 = dict(sharex=True, figsize=(9, n * 3))\n",
    "kwargs0.update(**kwargs)\n",
    "fig, axes = plt.subplots(n, 1, **kwargs0)\n",
    "axes = [axes] if n == 1 else axes\n",
    "for i, name in enumerate(forcing):\n",
    "    da = forcing[name].sel(time=trange)\n",
    "    longname = da.attrs.get(\"standard_name\", \"\")\n",
    "    unit = da.attrs.get(\"unit\", \"\")\n",
    "    prefix = \"\"\n",
    "    if da.ndim == 3:\n",
    "        da = da.mean(dim=[da.raster.x_dim, da.raster.y_dim])\n",
    "        prefix = \"mean \"\n",
    "    # convert to Single index dataframe (bar plots don't work with xarray)\n",
    "    df = da.squeeze().to_series()\n",
    "    if isinstance(df.index, pd.MultiIndex):\n",
    "        df = df.unstack(0)\n",
    "    # convert dates a-priori as automatic conversion doesn't always work\n",
    "    df.index = mdates.date2num(df.index)\n",
    "    if longname == \"precipitation\":\n",
    "        axes[i].bar(df.index, df.values, facecolor=\"darkblue\")\n",
    "        longname = 'runoff'\n",
    "    else:\n",
    "        # tide / disclim\n",
    "        da1 = mod1.forcing[name].sel(time=trange)\n",
    "        df1 = da1.squeeze().to_series().unstack(0)\n",
    "        df1.index = mdates.date2num(df1.index)\n",
    "        \n",
    "        bound = 'H' if longname == 'waterlevel' else 'Q'\n",
    "        cols = [1] if longname == 'waterlevel' else [0,3]\n",
    "        ylim = [df.values.min()*1.05, df.values.max()*1.3] if longname == 'waterlevel' else [0, df.values.max()*1.3]\n",
    "        j0 = 0 if longname == 'waterlevel' else 1\n",
    "        \n",
    "        # plot actual\n",
    "        suffix = 'tot' if longname == 'waterlevel' else 'event'\n",
    "        df.columns = [f'{bound}{i} - {suffix}' for i in df.columns.values]\n",
    "        for j, col in enumerate(df.columns[cols]):\n",
    "            df.loc[:,col].plot.line(ax=axes[i], c=colors[j+j0], label=col)\n",
    "            \n",
    "        # plot tide/clim\n",
    "        suffix = 'tide' if longname == 'waterlevel' else 'clim.'\n",
    "        df1.columns = [f'{bound}{i} - {suffix}' for i in df1.columns.values]\n",
    "        for j, col in enumerate(df1.columns[cols]):\n",
    "            df1.loc[:,col].plot.line(ax=axes[i], ls='--', color=colors[j+j0], label=col)\n",
    "\n",
    "\n",
    "        axes[i].legend(\n",
    "#             title=\"index\",\n",
    "            bbox_to_anchor=(1, 1),\n",
    "            loc=\"upper right\",\n",
    "            ncol=2,\n",
    "        )\n",
    "        axes[i].set_ylim(ylim)\n",
    "\n",
    "    axes[i].set_ylabel(f\"{prefix}{longname}\\n[{unit}]\")\n",
    "    axes[i].set_title(f\"{longname} boundary\")\n",
    "    axes[i].set_xlim([df.index[0], df.index[-1]])\n",
    "\n",
    "# use a concise date formatter for format date axis ticks\n",
    "locator = mdates.AutoDateLocator()\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "axes[-1].xaxis.set_major_locator(locator)\n",
    "axes[-1].xaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.savefig(join('figs', f'forcing_{event}.png'), dpi=225, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess EO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddir = r'..\\00_data\\EO\\RAPID\\Cyclone_Idai_2019'\n",
    "ddir = r'..\\00_data\\EO\\RAPID\\Cyclone_Eloise_2021'\n",
    "name = 'flooding'\n",
    "dstr = '20210125'\n",
    "fns = glob.glob(join(ddir, dstr, f'{name}*.tif'))\n",
    "\n",
    "da_lst = []\n",
    "for fn in fns:\n",
    "    da_obs0 = hydromt.open_raster(fn).load().astype(np.int8)\n",
    "    da_obs0.raster.set_nodata(-1)\n",
    "#     try:\n",
    "    da_obs0 = da_obs0.raster.reproject_like(mod0.staticmaps, method='max')\n",
    "    da_lst.append(da_obs0)\n",
    "#     except:\n",
    "#         print(fn)\n",
    "#         pass\n",
    "    \n",
    "da = xr.concat(da_lst, dim='img').max('img').load().astype(np.uint8)\n",
    "da = da.where(da==1,0)\n",
    "da.raster.set_nodata(0)\n",
    "da.raster.to_raster(join(mod0.root, '../EO', f'{name.lower()}_{dstr}.tif'), compress='deflate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstr = '20210125'\n",
    "\n",
    "da_lst = []\n",
    "for fn in glob.glob(join(mod0.root, '../EO', f'flooding_{dstr}*.tif')):\n",
    "    da_lst.append(hydromt.open_raster(fn).astype(np.int8))\n",
    "da_flood = xr.concat(da_lst, dim='img').max('img')\n",
    "\n",
    "da_lst = []\n",
    "for fn in glob.glob(join(mod0.root, '../EO', f'dry_{dstr}*.tif')):\n",
    "    da_lst.append(hydromt.open_raster(fn).astype(np.int8))\n",
    "if da_lst:\n",
    "    da_dry = xr.concat(da_lst, dim='img').max('img')\n",
    "    da_flood = da_flood.where(da_dry!=1, 0)\n",
    "    \n",
    "da_flood = da_flood.astype(np.uint8)\n",
    "da_flood.raster.set_nodata(0)\n",
    "da_flood.raster.to_raster(join(mod0.root, '../EO', f'flooding1_{dstr}_resampled_corrected.tif'), compress='deflate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read preprocessed EO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_lst = []\n",
    "dates = ['20190320', '20210125']\n",
    "for dstr in dates:\n",
    "    fn = join(mod0.root, '../EO', f'flooding_{dstr}_resampled_corrected.tif')\n",
    "    da_obs0 = hydromt.open_raster(fn, chunks={'x': -1, 'y':-1}).load()\n",
    "    da_obs = da_obs0.where(~da_mask, da_obs0.raster.nodata) == 1\n",
    "    da_lst.append(da_obs)\n",
    "da_obs = xr.concat(da_lst, dim='time')\n",
    "da_obs['time'] = xr.IndexVariable('time', pd.to_datetime(dates))\n",
    "da_obs.isel(time=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "\n",
    "cm_dict = {\n",
    "    1: ('false neg.', '#dd8452'),\n",
    "    2: ('false pos.', '#c44e52'),\n",
    "    3: ('true pos.', '#4c72b0'),\n",
    "}\n",
    "levels = [k for k,v in cm_dict.items()] + [4]\n",
    "colors = [v[1] for k,v in cm_dict.items()]\n",
    "ticklabs = [v[0] for k,v in cm_dict.items()]\n",
    "cmap, norm = mpl.colors.from_levels_and_colors(levels, colors)\n",
    "ticks = np.array(levels[:-1])+np.diff(levels)/2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compare CMF and SFINCS river bed levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cmf = hydromt.open_mfraster(r'../02_models/beira/cmf/beira_06min/*.tif')\n",
    "ds_cmf.raster.set_crs(4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "colrows = [(25,30), (27,30), (26, 25), (26,26), (28,28)]\n",
    "cols, rows = zip(*colrows)\n",
    "cols = xr.IndexVariable('index', np.asarray(cols)-1)\n",
    "rows = xr.IndexVariable('index', np.asarray(rows)-1)\n",
    "xs, ys = ds_cmf.isel(x=cols, y=rows)['lonlat'].values\n",
    "gdf_pnts = gpd.GeoDataFrame(geometry=gpd.points_from_xy(x=xs, y=ys), crs=4326)\n",
    "gdf_pnts.index = gdf_pnts.index+1\n",
    "gdf_pnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_cmf0 = ds_cmf.isel(x=cols, y=rows)\n",
    "ds_cmf0_zb = ds_cmf0['elevtn'] - ds_cmf0['rivdph_est_hc27_hp30']\n",
    "ds_cmf0_zb.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod0.staticmaps['dep'].raster.sample(gdf_pnts).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read CMF flood maps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read downscaled flood depth of all runs\n",
    "da_lst = []\n",
    "runs = []\n",
    "event = 'idai'\n",
    "for cmf_out in glob.glob(join('../02_models/beira/cmf/out', 'compound*')):\n",
    "    if event == 'idai':\n",
    "        da = xr.open_dataarray(join(cmf_out, event, 'flddph_20190310_20190325_3sec.nc'))\n",
    "    else:\n",
    "        da = xr.open_dataarray(join(cmf_out, event, 'flddph_20210118_20210201_3sec.nc'))\n",
    "    da.raster.set_crs(4326)\n",
    "    da = da.raster.reproject_like(mod0.staticmaps)\n",
    "    da_lst.append(da.load())\n",
    "    da.close()\n",
    "    runs.append(basename(cmf_out).replace('compound_rivdph_est_',''))\n",
    "da = xr.concat(da_lst, dim='run')\n",
    "da['run'] = xr.IndexVariable('run', runs)\n",
    "da.attrs.update(_FillValue=-9999)\n",
    "encoding = {'flddph': {'zlib': True}}\n",
    "da.to_netcdf(join('../02_models/beira/cmf/out', f'flddph_{event}_3sec.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event = 'eloise'\n",
    "tstr = dates[1]\n",
    "mdir = '../02_models/beira/cmf/out'\n",
    "hmin=0.25\n",
    "da = xr.open_dataarray(join(mdir, f'flddph_{event}_3sec.nc'))\n",
    "da_skill, da_cm = skill(da.sel(time=tstr), da_obs.sel(time=tstr), da_mask, hmin=hmin)\n",
    "df_skill = da_skill.reset_coords(drop=True).to_dataframe()\n",
    "df_skill.to_csv(join(mdir, f'flddph_{event}_hmin{hmin}.csv'))\n",
    "df_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivities = {\n",
    "    'bifprm': ['hc27_hp30_bifprm00', 'hc27_hp30_bifprm05', 'hc27_hp30'],\n",
    "    'rivhgt': ['hc25_hp25', 'hc27_hp30', 'hc30_hp30', 'hc35_hp35', 'hc40_hp40'],\n",
    "    'runoff': ['hc27_hp30_ro080', 'hc27_hp30', 'hc27_hp30_ro120'],\n",
    "}\n",
    "for s in sensitivities:\n",
    "    rows = np.ceil(len(sensitivities[s])/3)\n",
    "    da0 = da_cm.sel(run=sensitivities[s]).where(da_cm>0)\n",
    "    cbar_kwargs = dict(shrink=0.5, ticks=ticks)\n",
    "    obj = da0.plot(figsize=(15, 5*rows), cmap=cmap, norm=norm, add_colorbar=True, col='run', col_wrap=3, cbar_kwargs=cbar_kwargs)\n",
    "    obj.cbar.ax.set_yticklabels(ticklabs)\n",
    "    plt.savefig(join('../02_models/beira/cmf/out', f'flddph_{event}_{tstr}_{s}_3sec.png'), dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read all SFINCS flood maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdir = r'../02_models/beira/sfincs/'\n",
    "# IDAI runs < 10; eloise > 10\n",
    "event, runs = 'idai', glob.glob(join(mdir, '02_0*')) + glob.glob(join(mdir, '03_0*'))\n",
    "# event, runs = 'eloise', glob.glob(join(mdir, '02_1*')) + glob.glob(join(mdir, '03_1*'))\n",
    "\n",
    "da_lst = []\n",
    "names = []\n",
    "for root in runs:\n",
    "    mod = SfincsModel(root, mode='r')\n",
    "    mod.read_results()\n",
    "    da_hmax_fld = np.maximum(0, mod.results['zsmax'] - mod.results['zb']).rename({'timemax': 'time'})\n",
    "#     da_hmax_fld = np.maximum(0, mod.results['zs'] - mod.results['zb']).resample(time='1D').max('time')\n",
    "    da_lst.append(da_hmax_fld.rename('flddph'))\n",
    "    names.append(basename(root)[6:])\n",
    "    \n",
    "da = xr.concat(da_lst, dim='run')\n",
    "da['run'] = xr.IndexVariable('run', names)\n",
    "\n",
    "encoding = {'flddph': {'zlib': True}}\n",
    "da.to_netcdf(join(mdir, f'flddph_{event}.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdir = r'../02_models/beira/sfincs/'\n",
    "event = 'idai'\n",
    "tstr = dates[0]\n",
    "hmin=0.25\n",
    "da = xr.open_dataarray(join(mdir, f'flddph_{event}.nc'))\n",
    "da_skill, da_cm = skill(da.sel(time=tstr), da_obs.sel(time=tstr), da_mask, hmin=hmin)\n",
    "df_skill = da_skill.reset_coords(drop=True).to_dataframe()\n",
    "df_skill.to_csv(join(mdir, f'flddph_{event}_hmin{hmin}.csv'))\n",
    "df_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivities = {\n",
    "    'rivhgt': ['hc25_hp25_D4', 'htot_dis_precip', 'hc30_hp30_D4', 'hc35_hp35_D4', 'hc40_hp40_D4'],\n",
    "    'runoff': ['ro080', 'htot_dis_precip', 'ro120'],\n",
    "}\n",
    "for s in sensitivities:\n",
    "    rows = np.ceil(len(sensitivities[s])/3)\n",
    "    da0 = da_cm.sel(run=sensitivities[s]).where(da_cm>0)\n",
    "    cbar_kwargs = dict(shrink=0.5, ticks=ticks)\n",
    "    obj = da0.plot(figsize=(15, 5*rows), cmap=cmap, norm=norm, add_colorbar=True, col='run', col_wrap=3, cbar_kwargs=cbar_kwargs)\n",
    "    obj.cbar.ax.set_yticklabels(ticklabs)\n",
    "    plt.savefig(join(mdir, f'flddph_{event}_zs_hmin{hmin}_{s}.png'), dpi=300)\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## barplots\n",
    "sfx_rm = {\n",
    "    'ro120': '6. forcing\\n runoff 120%',\n",
    "    'ro080': '5. forcing\\n runoff 80%',\n",
    "    'hc35_hp35_D4': '4. river depth\\n a=0.35, b=0.35',\n",
    "    'hc30_hp30_D4': '3. river depth\\n a=0.30, b=0.30',\n",
    "    'hc25_hp25_D4': '2. river depth\\n a=0.25, b=0.25',\n",
    "    'htot_dis_precip': '1. default',\n",
    "}\n",
    "cmf_rm = {\n",
    "    'hc27_hp30_bifprm05': '8. floodplains\\n 5 bifurcation layers',\n",
    "    'hc27_hp30_bifprm00': '7. floodplains\\n no bifurcation',\n",
    "    'hc27_hp30_ro120': '6. forcing\\n runoff 120%',\n",
    "    'hc27_hp30_ro080': '5. forcing\\n runoff 80%',\n",
    "    'hc35_hp35': '4. river depth\\n a=0.35, b=0.35',\n",
    "    'hc30_hp30': '3. river depth\\n a=0.30, b=0.30',\n",
    "    'hc25_hp25': '2. river depth\\n a=0.25, b=0.25',\n",
    "    'hc27_hp30': '1. default',\n",
    "}\n",
    "event = 'idai'\n",
    "sfx_skill = pd.read_csv(join(r'../02_models/beira/sfincs/', f'flddph_{event}_hmin{hmin}.csv'), index_col=0)\n",
    "sfx_skill = sfx_skill.loc[sfx_rm.keys()].rename(sfx_rm)\n",
    "cmf_skill= pd.read_csv(join(r'../02_models/beira/cmf/out/', f'flddph_{event}_hmin{hmin}.csv'), index_col=0)\n",
    "cmf_skill = cmf_skill.loc[cmf_rm.keys()].rename(cmf_rm)\n",
    "event = 'eloise'\n",
    "sfx_skill1 = pd.read_csv(join(r'../02_models/beira/sfincs/', f'flddph_{event}_hmin{hmin}.csv'), index_col=0)\n",
    "sfx_skill1 = sfx_skill1.loc[sfx_rm.keys()].rename(sfx_rm)\n",
    "cmf_skill1= pd.read_csv(join(r'../02_models/beira/cmf/out/', f'flddph_{event}_hmin{hmin}.csv'), index_col=0)\n",
    "cmf_skill1 = cmf_skill1.loc[cmf_rm.keys()].rename(cmf_rm)\n",
    "\n",
    "csi = pd.concat([\n",
    "    cmf_skill['C'].rename('CaMa-Flood - Idai'),\n",
    "    cmf_skill1['C'].rename('CaMa-Flood - Eloise'),\n",
    "    sfx_skill['C'].rename('SFINCS - Idai'), \n",
    "    sfx_skill1['C'].rename('SFINCS - Eloise'), \n",
    "], axis=1)\n",
    "fr = pd.concat([\n",
    "    cmf_skill['F'].rename('CaMa-Flood - Idai'),\n",
    "    cmf_skill1['F'].rename('CaMa-Flood - Eloise'),\n",
    "    sfx_skill['F'].rename('SFINCS - Idai'), \n",
    "    sfx_skill1['F'].rename('SFINCS - Eloise'), \n",
    "], axis=1)\n",
    "hr = pd.concat([\n",
    "    cmf_skill['H'].rename('CaMa-Flood - Idai'),\n",
    "    cmf_skill1['H'].rename('CaMa-Flood - Eloise'),\n",
    "    sfx_skill['H'].rename('SFINCS - Idai'), \n",
    "    sfx_skill1['H'].rename('SFINCS - Eloise'), \n",
    "], axis=1)\n",
    "colors=['tab:blue', 'tab:purple', 'tab:green', 'tab:grey']\n",
    "colors=['tab:blue', 'cornflowerblue', 'green', 'tab:green']\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(15,6), sharey=True)\n",
    "kwargs = dict(color=colors, edgecolor='white', linewidth=1.5, width=0.8, legend=False, zorder=4)\n",
    "fr.plot.barh(ax=axs[2], **kwargs)\n",
    "hr.plot.barh(ax=axs[1], **kwargs).legend(\n",
    "    bbox_to_anchor=(0.5, 1.0),\n",
    "    loc=\"lower center\",\n",
    "    ncol=4,\n",
    "    fontsize=12\n",
    ")\n",
    "csi.plot.barh(ax=axs[0], **kwargs)\n",
    "axs[2].grid(axis='x')\n",
    "axs[2].set_xlim([0,0.55])\n",
    "axs[2].set_xlabel('false alarm rate [-]', fontsize=12)\n",
    "\n",
    "axs[1].set_xlim([0.2, 0.95])\n",
    "axs[1].set_xlabel('hit rate [-]', fontsize=12)\n",
    "axs[1].grid(axis='x')\n",
    "\n",
    "axs[0].set_xlim([0.2, 0.75])\n",
    "axs[0].set_xlabel('critical succes index [-]', fontsize=12)\n",
    "axs[0].set_ylabel('')\n",
    "axs[0].tick_params(labelsize=12)\n",
    "axs[0].grid(axis='x')\n",
    "\n",
    "# fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.05) \n",
    "plt.savefig(join('figs', f'sensitivity_floodextent.png'), dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# da0 = xr.open_dataarray(join(cmf_out, 'flddph_20210118_20210201_3sec.nc'))\n",
    "# da1 = xr.open_dataarray(join(cmf_out, 'flddph_20190310_20190328_3sec.nc'))\n",
    "# da = xr.concat([da0, da1], dim='time')\n",
    "# da.raster.set_crs(4326)\n",
    "# da_cmf = da.raster.reproject_like(mod0.staticmaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read sfincs\n",
    "# runs = [\n",
    "#     r'../02_models/beira/sfincs/03_01_htot_dis_precip',\n",
    "#     r'../02_models/beira/sfincs/04_eloise'\n",
    "# ]\n",
    "# da_lst = []\n",
    "# da_lst1 = []\n",
    "# for root in runs:\n",
    "#     mod = SfincsModel(root, mode='r')\n",
    "#     mod.read_results()\n",
    "#     da_hmax_fld = np.maximum(0, mod.results['zsmax'] - mod.results['zb']).rename({'timemax': 'time'})\n",
    "#     da_lst1.append(mod.results['zs'])\n",
    "#     da_lst.append(da_hmax_fld)\n",
    "# da_sfx = xr.concat(da_lst, dim='time')\n",
    "# da_sfx_zs = xr.concat(da_lst1, dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine runs\n",
    "da_sfx = xr.concat(\n",
    "    [xr.open_dataarray(r'../02_models/beira/sfincs/flddph_idai.nc').sel(run='htot_dis_precip'),\n",
    "    xr.open_dataarray(r'../02_models/beira/sfincs/flddph_eloise.nc').sel(run='htot_dis_precip')],\n",
    "    dim = 'time'\n",
    ")\n",
    "da_cmf = xr.concat(\n",
    "    [xr.open_dataarray(r'../02_models/beira/cmf/out/flddph_idai_3sec.nc').sel(run='hc27_hp30'),\n",
    "    xr.open_dataarray(r'../02_models/beira/cmf/out/flddph_eloise_3sec.nc').sel(run='hc27_hp30')],\n",
    "    dim = 'time'\n",
    ")\n",
    "#\n",
    "hmin=0.25\n",
    "scores = {'cmf': {}, 'sfx': {}}\n",
    "res = {'cmf': {}, 'sfx': {}}\n",
    "for tstr in dates:\n",
    "    scores['sfx'][tstr],  res['sfx'][tstr] = skill(da_sfx.sel(time=tstr), da_obs.sel(time=tstr), da_mask, hmin=hmin)\n",
    "    scores['cmf'][tstr],  res['cmf'][tstr] = skill(da_cmf.sel(time=tstr), da_obs.sel(time=tstr), da_mask, hmin=hmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, patheffects\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.crs as ccrs\n",
    "from string import ascii_lowercase\n",
    "\n",
    "# read crs and utm zone > convert to cartopy\n",
    "staticmaps = mod0.staticmaps\n",
    "wkt = staticmaps.raster.crs.to_wkt()\n",
    "if \"UTM zone \" not in wkt:\n",
    "    raise ValueError(\"Model CRS UTM zone not found.\")\n",
    "utm_zone = staticmaps.raster.crs.to_wkt().split(\"UTM zone \")[1][:3]\n",
    "utm = ccrs.UTM(int(utm_zone[:2]), \"S\" in utm_zone)\n",
    "extent = np.array(staticmaps.raster.box.buffer(100).total_bounds)[[0, 2, 1, 3]]\n",
    "props = dict( facecolor='w', alpha=0.8)\n",
    "\n",
    "ann_kwargs = dict(\n",
    "    xytext=(3, 3),\n",
    "    textcoords=\"offset points\",\n",
    "    zorder=4,\n",
    "    path_effects=[\n",
    "        patheffects.Stroke(linewidth=3, foreground=\"w\"),\n",
    "        patheffects.Normal(),\n",
    "    ],\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    nrows=2, figsize=(10,15),\n",
    "#     nrows=1, figsize=(10,8),\n",
    "    ncols=2,\n",
    "    subplot_kw={'projection': utm},\n",
    "    \n",
    "    sharex = True, sharey=True\n",
    ")\n",
    "axs = axs.flatten()\n",
    "d = {\n",
    "    'sfx': 'SFINCS',\n",
    "    'cmf': 'CaMa-Flood',\n",
    "    dates[0]: 'Idai',\n",
    "    dates[1]: 'Eloise',\n",
    "}\n",
    "\n",
    "for row, tstr in enumerate(dates):\n",
    "    for col, mod in enumerate(['cmf', 'sfx']):\n",
    "        i = int(row*2 + col)\n",
    "        ax = axs[i]\n",
    "        da_cm = res[mod][tstr]\n",
    "        da_skill = scores[mod][tstr]\n",
    "        hr, csi, fr = da_skill['H'].item(), da_skill['C'].item(), da_skill['F'].item()\n",
    "\n",
    "        da_mask.where(da_mask).plot(ax=ax, cmap='gray', add_colorbar=False, alpha=0.5)\n",
    "        cs = da_cm.where(da_cm>0).plot(ax=ax, cmap=cmap, norm=norm, add_colorbar=False)\n",
    "#         if row == 0:\n",
    "#             gdf_pnts.to_crs(da_cm.raster.crs).plot(ax=ax)\n",
    "#         for label, gdf_row in gdf_pnts.to_crs(da_cm.raster.crs).iterrows():\n",
    "#             x, y = gdf_row.geometry.x, gdf_row.geometry.y\n",
    "# #             ax.plot(x, y, color='k', marker='o')\n",
    "#             ax.annotate(label, xy=(x, y), **ann_kwargs)\n",
    "            \n",
    "        ax.yaxis.set_visible(True)\n",
    "        ax.xaxis.set_visible(True)\n",
    "        ax.text(0.82, 0.88, f'C: {csi:.2f}\\nH: {hr:.2f}\\nF: {fr:.2f}', transform=ax.transAxes, bbox=props)\n",
    "\n",
    "        if col == 0:\n",
    "            ax.set_ylabel(f\"y coordinate UTM zone {utm_zone} [m]\")\n",
    "        else:\n",
    "            ax.set_ylabel('')\n",
    "        \n",
    "        l = ascii_lowercase[i]\n",
    "        ax.set_title(f'{l}) {d[mod]} - {d[tstr]} ({tstr})')\n",
    "        if i >= len(axs)-2:\n",
    "            ax.set_xlabel(f\"x coordinate UTM zone {utm_zone} [m]\")   \n",
    "        else:\n",
    "            ax.set_xlabel('')\n",
    "            \n",
    "ax.set_xticks(ax.get_xticks()[::2])\n",
    "ax.set_extent(extent, crs=utm)\n",
    "fig.subplots_adjust(wspace=0.05, hspace=0.06)\n",
    "\n",
    "# # Add a colorbar axis at the bottom of the graph\n",
    "cbar_ax = fig.add_axes([0.93, 0.33, 0.015, 0.3])\n",
    "\n",
    "# # Draw the colorbar\n",
    "cbar=fig.colorbar(cs, cax=cbar_ax, orientation='vertical', ticks=ticks)\n",
    "cbar_ax.set_yticklabels(ticklabs)\n",
    "\n",
    "plt.savefig(join('figs', f'obs_vs_sim_hmin25.png'), dpi=500, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timeseries plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SFINCS waterlevels for combined idai + eloise runs for all forcing scenarios\n",
    "\n",
    "mdir = r'../02_models/beira/sfincs/'\n",
    "# IDAI runs < 10; eloise > 10\n",
    "event, runs = 'idai', glob.glob(join(mdir, '03_0*'))\n",
    "da_lst = []\n",
    "names = []\n",
    "for root in runs:\n",
    "    mod = SfincsModel(root, mode='r')\n",
    "    mod.read_results()\n",
    "    da_lst.append(mod.results['zs'])\n",
    "    names.append(basename(root)[6:])\n",
    "da0 = xr.concat(da_lst, dim='run')\n",
    "da0['run'] = xr.IndexVariable('run', names)\n",
    "\n",
    "event, runs = 'eloise', glob.glob(join(mdir, '03_1*'))\n",
    "da_lst = []\n",
    "names = []\n",
    "for root in runs:\n",
    "    mod = SfincsModel(root, mode='r')\n",
    "    mod.read_results()\n",
    "    da_lst.append(mod.results['zs'])\n",
    "    names.append(basename(root)[6:])\n",
    "da1 = xr.concat(da_lst, dim='run')\n",
    "da1['run'] = xr.IndexVariable('run', names)\n",
    "\n",
    "da_sfx_zs = xr.concat([da0, da1], dim='time').round(2)\n",
    "\n",
    "encoding = {'zs': {'zlib': True, 'dtype': 'float32'}}\n",
    "da_sfx_zs.to_netcdf(join(mdir, f'zs_compound.nc'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read SFINCS data\n",
    "mdir = r'../02_models/beira/sfincs/'\n",
    "\n",
    "da_sfx_zs = xr.open_dataarray(join(mdir, f'zs_compound.nc'), chunks={'run':1})\n",
    "da_sfx_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CMF waterlevels for combined idai + eloise runs\n",
    "cmf_out = r'../02_models/beira/cmf/out/compound_rivdph_est_hc27_hp30'\n",
    "da_cmf_zs = xr.open_mfdataset(join(cmf_out, '*', 'o_flddph*'), concat_dim='time')['flddph'].rename('zs')\n",
    "da_cmf_zs = da_cmf_zs + ds_cmf['elevtn'].raster.reproject_like(da_cmf_zs)\n",
    "da_cmf_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load timeseries data at obs points\n",
    "\n",
    "da_cmf_zs0 = da_cmf_zs.isel(lon=cols, lat=rows).sel(time=trange).load() #.plot.line(x='time')\n",
    "da_cmf_zs0['index'] = xr.IndexVariable('index', gdf_pnts.index.values)\n",
    "# df_cmf = da_cmf_zs0.to_series.unstack(0)\n",
    "# df_cmf.index = mdates.date2num(df_cmf.index)\n",
    "\n",
    "da_sfx_zs0 = da_sfx_zs.sel(time=trange, run='htot_dis_precip').raster.sample(gdf_pnts).load()#.plot.line(x='time')\n",
    "da_sfx_zs0['index'] = xr.IndexVariable('index', gdf_pnts.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot \n",
    "n = 2\n",
    "kwargs0 = dict(sharex=True, figsize=(9, n * 3))\n",
    "fig, (ax, ax1) = plt.subplots(n, 1, **kwargs0)\n",
    "colors = ['darkblue', 'darkgreen', 'lightblue', 'darkmagenta', 'orangered']\n",
    "\n",
    "# df.index = mdates.date2num(df.index)\n",
    "j = 0\n",
    "for i in range(1,3):\n",
    "    da_sfx_zs0.sel(index=i).plot.line(ax=ax, x='time', color=colors[j], label=f'loc {i} - SFINCS')\n",
    "    da_cmf_zs0.sel(index=i).plot.line(ax=ax, x='time', color=colors[j], ls='--', label=f'loc {i} - CaMa-Flood')\n",
    "    j += 1\n",
    "ax.set_title('Buzi River')\n",
    "ax.set_ylabel('waterlevel [m+EGM96]')\n",
    "ax.set_xlabel('')\n",
    "ax.legend(\n",
    "    title=\"index\",\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    ncol=1,\n",
    ")\n",
    "\n",
    "for i in range(3,6):\n",
    "    da_sfx_zs0.sel(index=i).plot.line(ax=ax1, x='time', color=colors[j], label=f'loc {i} - SFINCS')\n",
    "    da_cmf_zs0.sel(index=i).plot.line(ax=ax1, x='time', color=colors[j], ls='--', label=f'loc {i} - CaMa-Flood')\n",
    "    j += 1\n",
    "ax1.set_title('Pungwe River')\n",
    "ax1.set_ylabel('waterlevel [m+EGM96]')\n",
    "ax1.legend(\n",
    "    title=\"index\",\n",
    "    bbox_to_anchor=(1.02, 1),\n",
    "    loc=\"upper left\",\n",
    "    ncol=1,\n",
    ")\n",
    "ax1.set_xlim([da_sfx_zs0.time.values[0], da_sfx_zs0.time.values[-1]])\n",
    "\n",
    "# use a concise date formatter for format date axis ticks\n",
    "locator = mdates.AutoDateLocator()\n",
    "formatter = mdates.ConciseDateFormatter(locator)\n",
    "ax1.xaxis.set_major_locator(locator)\n",
    "ax1.xaxis.set_major_formatter(formatter)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.savefig(join('figs', f'sfincs_vs_cmf_timeseries_idai.png'), dpi=225, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_pnts1 = gpd.GeoDataFrame(geometry=gpd.points_from_xy(x=[34.78024, 34.78508],y=[-19.82118, -19.83855]), crs=4326)\n",
    "gdf_pnts1 = gdf_pnts.loc[[2,5],]\n",
    "da_sfx_zs0 = da_sfx_zs.sel(time=trange).raster.sample(gdf_pnts1).load()#.plot.line(x='time')\n",
    "da_sfx_zs0['index'] = xr.IndexVariable('index', gdf_pnts1.index.values)\n",
    "\n",
    "n = da_sfx_zs0.index.size\n",
    "kwargs0 = dict(sharex=True, figsize=(9, n * 3))\n",
    "fig, axs = plt.subplots(n, 1, **kwargs0)\n",
    "\n",
    "rm = {\n",
    "    'htide_disclim_precip': 'Pluvial',\n",
    "    'htide_dis_noprecip': 'Fluvial',\n",
    "    'htot_disclim_noprecip': 'Coastal',\n",
    "    'htot_dis_precip': 'Compound',\n",
    "}\n",
    "for i, idx in enumerate(gdf_pnts1.index):\n",
    "    da0 = da_sfx_zs0.sel(index=idx).sel(run=list(rm.keys()))\n",
    "    lines = da0.plot.line(x='time', ax=axs[i], add_legend=False)\n",
    "    axs[i].set_ylabel('waterlevel [m+EGM96]')\n",
    "    axs[i].set_title(f'loc {idx}')\n",
    "    axs[i].set_xlabel('')\n",
    "    if i == 0:\n",
    "        axs[0].legend(\n",
    "            lines,\n",
    "            labels=list(rm.values()),\n",
    "            title=\"scenarios\",\n",
    "            bbox_to_anchor=(1.02, 1),\n",
    "            loc=\"upper left\",\n",
    "            ncol=1,\n",
    "        )\n",
    "axs[-1].set_xlim([da_sfx_zs0.time.values[0], da_sfx_zs0.time.values[-1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read & plot SFINCS runs (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "mdir = r'../02_models/beira/sfincs'\n",
    "runs = glob.glob(join(mdir, '01_b*')) + glob.glob(join(mdir, '02*')) + glob.glob(join(mdir, '03_*'))\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame(columns=['csi', 'hit_rate', 'miss_rate', 'inf_mean', 'inf_max'], dtype=np.float32)\n",
    "mods ={}\n",
    "tstr = '20190321'\n",
    "tstr = 'max'\n",
    "mask, write, plot = False, False, False\n",
    "\n",
    "for root in runs:\n",
    "\n",
    "    name = basename(root)[3:]\n",
    "    print(name)\n",
    "    mod = SfincsModel(root, mode='r')\n",
    "    mod.read_results()\n",
    "    if tstr == 'max':\n",
    "        da_hmax_fld = mod.results['hmax']\n",
    "    else:\n",
    "        da_hmax_fld = np.maximum(0, mod.results['zsmax'].sel(timemax=tstr) - mod.results['zb'])\n",
    "        da_hmax_fld.raster.set_nodata(mod.results['hmax'].raster.nodata)\n",
    "    if mask:\n",
    "        da_hmax_fld = da_hmax_fld.where(~da_mask, mod.results['hmax'].raster.nodata)\n",
    "    if mask or tstr != 'max':\n",
    "        mod.set_results(da_hmax_fld, f'h{tstr}')\n",
    "    if write and not isfile(join(mod.root, 'gis', f'h{tstr}.tif')):\n",
    "        mod.write_raster(f'results.h{tstr}')\n",
    "    \n",
    "    csi, hit_rate, miss_rate, da_cm = skill(da_hmax_fld, da_obs, da_mask)\n",
    "    df.loc[name, ['csi', 'hit_rate', 'miss_rate']] = csi, hit_rate, miss_rate\n",
    "#     df.loc[name, 'inf_mean'] = float(mod.results['cuminf'].mean())\n",
    "#     df.loc[name, 'inf_max'] = float(mod.results['cuminf'].max())\n",
    "    mod.set_results(da_cm, f'cm{tstr}')\n",
    "    mods[name] = mod\n",
    "    \n",
    "#     if plot:\n",
    "    if not isfile(join(mod.root, 'figs', f'obs_vs_sim_{tstr}.png')):\n",
    "        # fig, ax = mod.plot_basemap(fn_out=None, variable=None, bmap='sat', geoms=[], plot_bounds=False)\n",
    "        fig, ax = mod.plot_basemap(fn_out=None, variable=None, bmap='', zoomlevel=12, geoms=[], plot_bounds=False)\n",
    "#         ax.add_image(cimgt.Stamen(style='toner-background'), 11, cmap='gray', alpha=0.5)\n",
    "        da_mask.where(da_mask).plot(ax=ax, cmap='gray', add_colorbar=False, alpha=0.5)\n",
    "        p = da_cm.where(da_cm>0).plot(cmap=cmap, norm=norm, cbar_kwargs=dict(ticks=ticks, shrink=0.3, anchor=(0,0)))\n",
    "        _ =p.colorbar.ax.set_yticklabels(ticklabs)\n",
    "        ax.set_title(f'Observed vs simulated flood extent\\n (HR = {hit_rate:0.2f}, CSI = {csi:0.2f})')\n",
    "        if not os.path.isdir(join(mod.root, 'figs')):\n",
    "            os.makedirs(join(mod.root, 'figs'))\n",
    "        plt.savefig(join(mod.root, 'figs', f'obs_vs_sim_{tstr}.png'), dpi=225, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "    \n",
    "    \n",
    "df = df.round(3)\n",
    "df.to_csv(join(mdir, f'sfincs_{tstr}_results.csv'))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, tstr = 'eloise', '20210125'\n",
    "# name, tstr = 'idai', '20190321'\n",
    "root = join(join(mdir, f'04_{name}'))\n",
    "mod = SfincsModel(root, mode='r')\n",
    "da_hmax_fld = np.maximum(0, mod.results['zsmax'].sel(timemax=tstr) - mod.results['zb'])\n",
    "# mod = mods[name]\n",
    "# da_cm = mod.results[f'cm{tstr}']\n",
    "# csi, hit_rate = df.loc[name, ['csi', 'hit_rate']]\n",
    "csi, hit_rate, miss_rate, da_cm = skill(da_hmax_fld, da_obs, da_mask)\n",
    "da_cm.attrs = {}\n",
    "da_cm.name = None\n",
    "\n",
    "# fig, ax = mod.plot_basemap(fn_out=None, variable=None, bmap='sat', geoms=[], plot_bounds=False)\n",
    "fig, ax = mod.plot_basemap(fn_out=None, variable=None, bmap='', zoomlevel=12, geoms=[], plot_bounds=False)\n",
    "# ax.add_image(cimgt.Stamen(style='toner-background'), 11, cmap='gray', alpha=0.5)\n",
    "da_mask.where(da_mask).plot(ax=ax, cmap='gray', add_colorbar=False, alpha=0.5)\n",
    "p = da_cm.where(da_cm>0).plot(cmap=cmap, norm=norm, cbar_kwargs=dict(ticks=ticks, shrink=0.3, anchor=(0,0)))\n",
    "_ =p.colorbar.ax.set_yticklabels(ticklabs)\n",
    "ax.set_title(f'Observed vs simulated flood extent\\n (HR = {hit_rate:0.2f}, CSI = {csi:0.2f})')\n",
    "if not os.path.isdir(join(mod.root, 'figs')):\n",
    "    os.makedirs(join(mod.root, 'figs'))\n",
    "plt.savefig(join(mod.root, 'figs', f'obs_vs_sim_{tstr}.png'), dpi=225, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read all SFINCS runs into single dataset for compound dynamic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "mdir = r'../02_models/beira/sfincs'\n",
    "runs = glob.glob(join(mdir, '03_*'))\n",
    "print(runs)\n",
    "ts = pd.date_range('201903130000', '201903240000', freq='24H')\n",
    "mods = {}\n",
    "for root in runs:\n",
    "    name = basename(root)[3:]\n",
    "    mod = SfincsModel(root, mode='r')\n",
    "    da_fld = np.maximum(0, mod.results['zsmax'] - mod.results['zb']).rename({'timemax': 'time'})\n",
    "    mods[name] = da_fld.sel(time=ts, method='nearest').fillna(0).load()\n",
    "#     mods[name] = np.maximum(mod.results['zsmax'], mod.results['zb']).sel(time=ts, method='nearest').load()\n",
    "    mods[name].name = name\n",
    "    mods[name].close()\n",
    "\n",
    "da0 = xr.concat(mods.values(), dim='scen')\n",
    "da0['scen'] = xr.IndexVariable('scen', list(mods.keys()))\n",
    "\n",
    "da0 = da0.round(3).rename('flddph')\n",
    "da0.to_netcdf('sfincs_compound1.nc', encoding={'flddph': {'zlib': True}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_mask_int = mod0.staticmaps['rivmsk']\n",
    "gdf = da_mask_int.raster.vectorize()\n",
    "# gdf.boundary.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event, ts = 'idai', pd.date_range('201903140000', '201903220000', freq='24H')\n",
    "event, ts = 'eloise', pd.date_range('202101190000', '202101270000', freq='24H')\n",
    "\n",
    "mdir = r'../02_models/beira/sfincs/'\n",
    "\n",
    "da0 = xr.open_dataarray(join(mdir, f'flddph_{event}.nc')).sel(time=ts, method='nearest').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append timemax to time dim\n",
    "hmin = 0.25\n",
    "\n",
    "da3 = da0.resample(time='3D').max('time')\n",
    "da_max = da3.max('time').expand_dims('time')\n",
    "da_max['time'] = xr.IndexVariable('time', [da0.time.max().values])\n",
    "# fldmsk = da_max.sel(scen='01_htot_dis_precip').squeeze() > hmin\n",
    "da = xr.concat([da3, da_max], dim='time').load()\n",
    "da = da.where(da > hmin, 0).rename({'run': 'scen'})\n",
    "da.chunk({'time':-1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create SFINCS compound driver array\n",
    "import matplotlib\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "dh =  0.02\n",
    "\n",
    "da_single_max = da.sel(scen=['htide_dis_noprecip', 'htot_disclim_noprecip', 'htide_disclim_precip', 'htide_disclim_noprecip']).max('scen')\n",
    "compound_diff = (da.sel(scen='htot_dis_precip') - da_single_max).compute()\n",
    "compound_diff.name = 'diff. in waterlevel\\ncompound - max. single driver'\n",
    "compound_diff.attrs.update(unit='m')\n",
    "\n",
    "compound_mask = compound_diff > dh\n",
    "surge_mask = da.sel(scen='htot_disclim_noprecip') > da.sel(scen=['htide_disclim_precip', 'htide_dis_noprecip']).max('scen')\n",
    "discharge_mask = da.sel(scen='htide_dis_noprecip') > da.sel(scen=['htot_disclim_noprecip', 'htide_disclim_precip']).max('scen')\n",
    "precip_mask = da.sel(scen='htide_disclim_precip') > da.sel(scen=['htot_disclim_noprecip', 'htide_dis_noprecip']).max('scen') \n",
    "precip_mask = np.logical_and(precip_mask, compound_diff>=0)\n",
    "assert ~np.logical_and(precip_mask, surge_mask).any() and ~np.logical_and(discharge_mask, surge_mask).any() and ~np.logical_and(discharge_mask, precip_mask).any()\n",
    "\n",
    "da_cmpnd = (\n",
    "    xr.where(surge_mask, compound_mask+1, 0)\n",
    "    + xr.where(discharge_mask, compound_mask + 3, 0)\n",
    "    + xr.where(precip_mask, compound_mask + 5, 0)\n",
    ").compute()\n",
    "da_cmpnd.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, patheffects\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.crs as ccrs\n",
    "from string import ascii_lowercase\n",
    "import datetime\n",
    "\n",
    "# read crs and utm zone > convert to cartopy\n",
    "staticmaps = mod0.staticmaps\n",
    "wkt = staticmaps.raster.crs.to_wkt()\n",
    "utm_zone = staticmaps.raster.crs.to_wkt().split(\"UTM zone \")[1][:3]\n",
    "utm = ccrs.UTM(int(utm_zone[:2]), \"S\" in utm_zone)\n",
    "extent = np.array(staticmaps.raster.box.buffer(100).total_bounds)[[0, 2, 1, 3]]\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('tab20c')\n",
    "levels = np.arange(1,8)\n",
    "colors = np.array(cmap.colors)[[2,0,14,12,10,8]]\n",
    "cmap, norm = mpl.colors.from_levels_and_colors(levels, colors)\n",
    "\n",
    "\n",
    "dates = compound_diff.time\n",
    "n = len(dates)\n",
    "fig, axs = plt.subplots(\n",
    "#     nrows=2, figsize=(10,15),\n",
    "    nrows=2, figsize=(4.5*n, 12),\n",
    "    ncols=n,\n",
    "    subplot_kw={'projection': utm},\n",
    "    sharex = True, sharey=True, \n",
    ")\n",
    "axs = axs.flatten()\n",
    "\n",
    "for row, time in enumerate(dates):\n",
    "\n",
    "    # dh\n",
    "    da_t= compound_diff.sel(time=time)\n",
    "    if row == len(dates)-1:\n",
    "        tstr = 'total'\n",
    "    else:\n",
    "        t1 = da_t.time + int(3*86400*1e9) # nano sec\n",
    "        tstr0 = da_t.time.dt.strftime(\"%d\").item()\n",
    "        tstr1 = t1.dt.strftime(\"%d %b %Y\").item()\n",
    "        tstr = f'{tstr0}-{tstr1}'\n",
    "        \n",
    "    i = row\n",
    "    dep_mask.where(dep_mask).plot(ax=axs[i], cmap='gray', add_colorbar=False, alpha=0.5)\n",
    "    ckwargs = dict(cmap='seismic', vmin=-0.25, vmax=0.25)\n",
    "    cs = da_t.where(np.abs(da_t)>dh).plot(ax=axs[i], add_colorbar=False, **ckwargs)\n",
    "    gdf.boundary.plot(ax=axs[i], ls='--', lw=0.5, color='k', alpha=0.5)\n",
    "    \n",
    "    # driver\n",
    "    da_c = da_cmpnd.sel(time=time)\n",
    "    j = row + n\n",
    "    dep_mask.where(dep_mask).plot(ax=axs[j], cmap='gray', add_colorbar=False, alpha=0.5)\n",
    "    p = da_c.where(da_c>0).plot(ax=axs[j], cmap=cmap, norm=norm, add_colorbar=False)\n",
    "    gdf.boundary.plot(ax=axs[j], ls='--', lw=0.5, color='k', alpha=0.5)\n",
    "\n",
    "    axs[i].set_title(tstr)\n",
    "    axs[j].set_title('')\n",
    "    axs[i].set_extent(extent, crs=utm)\n",
    "    axs[j].set_extent(extent, crs=utm)\n",
    "\n",
    "    if row == 0:\n",
    "        axs[i].yaxis.set_visible(True)\n",
    "        axs[i].set_ylabel(f\"y coordinate UTM zone {utm_zone} [m]\")\n",
    "        axs[j].yaxis.set_visible(True)\n",
    "        axs[j].set_ylabel(f\"y coordinate UTM zone {utm_zone} [m]\")\n",
    "    axs[j].xaxis.set_visible(True)\n",
    "    axs[j].set_xlabel(f\"x coordinate UTM zone {utm_zone} [m]\")\n",
    "\n",
    "axs[j].set_xticks(axs[j].get_xticks()[1::2])\n",
    "fig.subplots_adjust(wspace=0.03, hspace=0.05)\n",
    "\n",
    "# add colormap dh\n",
    "pos0 = axs[i].get_position() # get the original position \n",
    "cax = fig.add_axes([pos0.x1 + 0.01, pos0.y0 + pos0.height*0.15, 0.015, pos0.height*0.7])\n",
    "label = 'diff. waterlevel [m]\\ncompound - max. single driver'\n",
    "cbar=fig.colorbar(cs, cax=cax, orientation='vertical', label=label, extend='both')\n",
    "\n",
    "# Add a colorbar drivers\n",
    "pos1 = axs[j].get_position() # get the original position \n",
    "cbar_ax = fig.add_axes([pos1.x1 + 0.01, pos1.y0 + pos0.height*0.25,  0.05, pos0.height*0.5] )\n",
    "cm = np.arange(1,7).reshape((3,2))\n",
    "cbar_ax.imshow(cm, cmap=cmap, norm=norm, aspect='auto')\n",
    "cbar_ax.yaxis.tick_right()\n",
    "cbar_ax.set_yticks([0,1,2])\n",
    "cbar_ax.set_yticklabels(['coastal', 'fluvial', 'pluvial'], va='center', rotation=90)\n",
    "cbar_ax.set_xticks([0,1])\n",
    "cbar_ax.set_xticklabels(['single', 'compound'], ha='center', rotation=60)\n",
    "\n",
    "plt.savefig(join('figs', f'sfincs_{event}_compound_zsmax_3d_v1.png'), dpi=225, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# simulation waterdepth run plot\n",
    "name = '01_htot_dis_precip'\n",
    "for time in da.time:\n",
    "    t = time.dt.strftime(\"%Y-%m-%d %H:%M\").item()\n",
    "    tstr = time.dt.strftime(\"%Y%m%dT%H%M\").item()\n",
    "    # sfincs\n",
    "#     fn_out = join(mdir, f'03_{name}', 'figs', f'h{tstr}.png')\n",
    "#     da_t = da.sel(scen=name, time=time)\n",
    "    # cmf\n",
    "    root = join('../02_models/beira/sfincs/', f'03_{name}')\n",
    "    fn_out = join(root, 'figs', f'h{tstr}.png')\n",
    "    da_t = mods[name].sel(time=time)\n",
    "    print(t)\n",
    "    \n",
    "    fig, ax = mod.plot_basemap(fn_out=None, variable=None, bmap='sat', geoms=[], plot_bounds=False)\n",
    "#     ax.add_image(cimgt.Stamen(style='toner-background'), 11, cmap='gray', alpha=0.5)\n",
    "    da_mask.where(da_mask).plot(ax=ax, cmap='gray', add_colorbar=False, alpha=0.5)\n",
    "    p = da_t.where(da_t>0).plot(cmap='BuPu', vmin=0, vmax=5, cbar_kwargs=dict(shrink=0.5, anchor=(0,0)))\n",
    "    gdf.boundary.plot(ls='--', lw=0.5, color='k', alpha=0.5, ax=ax)\n",
    "    ax.set_title(f'Flood depth {t}')\n",
    "    plt.savefig(fn_out, dpi=225, bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 variable compound plot\n",
    "import matplotlib\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "dh =  0.01\n",
    "hmin = 0.20\n",
    "\n",
    "da = da.where(da.sel(scen='01_htot_dis_precip') > hmin, 0)\n",
    "da_single_max = da.sel(scen=['04_htide_dis_noprecip', '06_htot_disclim_noprecip']).max('scen')\n",
    "da_max = da.max('scen')\n",
    "mask = da_max > hmin\n",
    "\n",
    "da_discharge = da.sel(scen='02_htot_dis_noprecip')  > (da_single_max + dh)\n",
    "da_surge = da.sel(scen='02_htot_dis_noprecip')  > (da_single_max + dh)\n",
    "\n",
    "compound_mask = da.sel(scen='01_htot_dis_precip') > (da_single_max + dh)\n",
    "surge_mask = da.sel(scen='06_htot_disclim_noprecip') > da.sel(scen='04_htide_dis_noprecip')\n",
    "discharge_mask = da.sel(scen='04_htide_dis_noprecip') > da.sel(scen='06_htot_disclim_noprecip')\n",
    "\n",
    "da_cmpnd = (\n",
    "    xr.where(surge_mask, da_surge+1, 0)\n",
    "    + xr.where(discharge_mask, da_discharge+5, 0)\n",
    ").where(mask, 0)\n",
    "da_cmpnd.name = None\n",
    "cmap0 = matplotlib.cm.get_cmap('tab20c')\n",
    "levels = np.arange(1,8)\n",
    "colors = np.array(cmap0.colors)[[2,0,10,8,14,12]]\n",
    "cmap, norm = mpl.colors.from_levels_and_colors(levels, colors)\n",
    "ticks = np.array(levels[:-1])+np.diff(levels)/2.\n",
    "ticklabs = ['coastal', 'coastal - compound', 'pluvial', 'pluvial - compound', 'fluvial', 'fluvial - compound']\n",
    "\n",
    "fig, ax = mod.plot_basemap(fn_out=None, variable=None, bmap='', zoomlevel=12, geoms=[], plot_bounds=False)\n",
    "ax.add_image(cimgt.Stamen(style='toner-background'), 11, cmap='gray', alpha=0.5)\n",
    "p = da_cmpnd.where(da_cmpnd>0).plot(cmap=cmap, norm=norm, cbar_kwargs=dict(ticks=ticks, shrink=0.5, anchor=(0,0)))\n",
    "gdf.boundary.plot(ls='--', lw=0.5, color='k', alpha=0.5, ax=ax)\n",
    "_ =p.colorbar.ax.set_yticklabels(ticklabs)\n",
    "ax.set_title(f'Flood drivers maximum water depth cyclone Idai')\n",
    "plt.savefig(join('figs', f'drivers2_{tstr}.png'), dpi=225, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
